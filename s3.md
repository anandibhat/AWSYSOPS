##### S3
* **Versioning’s Multi-Factor Authentication (MFA) Delete** capability can be used to provide an additional layer of security. By default, all requests to your Amazon S3 bucket require your AWS account credentials. If you enable Versioning with MFA Delete on your Amazon S3 bucket, two forms of authentication are required to permanently delete a version of an object: your AWS account credentials and a valid six-digit code and serial number from an authentication device in your physical possession.
* **Server Side Encryption (SSE/SSE-S3)**. You can securely upload/download your data to Amazon S3 via SSL endpoints using the HTTPS protocol. If you need extra security you can use the Server-Side Encryption (SSE) option to encrypt data stored at rest. You can configure your Amazon S3 buckets to automatically encrypt objects before storing them if the incoming storage requests do not have any encryption information. **AWS handles key management and key protection** using multiple layers of security.
* **SSE-C** Manage encryption keys by yourself. Use when you don't need to use client-side encryption library to encrypt keys.
* **SSE-KMS** Manage keys by AWS service. Thanks to this more granural permission level (S3 & key itself) security is allowed, keys have separate permissions, audit trail log is available for keys usage, rotation is done by AWS, view failed attempts to access data from users without permission to decrypt the data.
* **Encryption client library**  Use when you want to **control whole process** of object encryption to S3. Encryption is done on client side (encrypted objects are transmitted over the Internet to Amazon S3).


* S3 Durability - 11 nines! 99.999999999%
* S3 max object size 5 TB
  * By default max uploaded object size is 5GB. Docs [here](https://aws.amazon.com/blogs/aws/amazon-s3-multipart-upload/)
  * In order to store more than 5GB use _Multipart Upload API_ (before uploading it's required to separate file into parts: **logical** or **physical**)
  * Amazon S3 does the bookkeeping behind the scenes for our customers, so you can now GET that large object just like you would any other Amazon S3 object.
* [IAM Policies, Bucket Policies, Bucket ACLs](https://aws.amazon.com/blogs/security/iam-policies-and-bucket-policies-and-acls-oh-my-controlling-access-to-s3-resources/)
* Pre-signed URLs. Use when **NO** need to create AWS credentials. When accessing presigned URL, user must specify: *username, password, expiration date, HTTP method, bucket name, object key.* Pre-signed URLs are valid for specific time interval.

#### Cross-region replication:
* source & destination buckets must have **versioning** enabled
* source & destintaion buckets must be in **different aws regions**
* s3 must have permissions to replicate object from source to destination bucket

**Reduced latency, security, disaster recovery, and other use cases:**
* CRR (cross-region replication)
* SRR (single-region replication)

#### Restriced access OAI (origin access identity)
It is possible to restrict acces to S3 Bucket to be accessible only from cloudfront.
1. Create a special CloudFront user called an origin access identity (OAI) and associate it with your distribution.

2. Configure your S3 bucket permissions so that CloudFront can use the OAI to access the files in your bucket and serve them to your users. Make sure that users can’t use a direct URL to the S3 bucket to access a file there.





**TODO:** AWS Import/Export, AWS snowball
